{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR='./data/shakespeare.txt'\n",
    "BATCH_SIZE=100\n",
    "LAYER_NUM=2\n",
    "SEQ_LENGTH=100\n",
    "HIDDEN_DIM=128\n",
    "GENERATE_LEN=500\n",
    "NB_EPOCH=150\n",
    "MODE='train'\n",
    "WEIGHTS=''\n",
    "LEARNING_RATE=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_data():\n",
    "    with open(DATA_DIR,\"r\") as text_file:\n",
    "        data=text_file.read()\n",
    "        data=data.replace('\\n','')\n",
    "        data=data.replace('$','')\n",
    "    lis=list(set(data))    \n",
    "    total_char,unique_char=len(data),len(lis)\n",
    "    print ('data has %d characters, %d unique.' %(total_char, unique_char))\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(lis) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(lis) }\n",
    "    return total_char,unique_char,char_to_ix,ix_to_char,data\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1075393 characters, 63 unique.\n"
     ]
    }
   ],
   "source": [
    "total_chars,unique_chars,char_id,id_char,data=get_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 0, 'a': 1, 'C': 2, 'z': 3, 'r': 4, ';': 5, 'K': 6, 'V': 7, 'H': 8, 'n': 9, 'L': 10, 'd': 11, 'Y': 12, 'Q': 13, ':': 14, 'k': 15, 'g': 16, 'F': 17, 'G': 18, 'E': 19, 'w': 20, 'O': 21, 't': 22, '-': 23, '&': 24, 'o': 25, 'X': 26, 'y': 27, '!': 28, 'l': 29, 'p': 30, 'h': 31, 'q': 32, '3': 33, 'T': 34, '.': 35, 'R': 36, ',': 37, 'S': 38, 'N': 39, 'c': 40, 'j': 41, 'B': 42, 'W': 43, 'f': 44, 's': 45, ' ': 46, 'b': 47, 'i': 48, 'm': 49, 'e': 50, 'M': 51, 'P': 52, 'A': 53, \"'\": 54, '?': 55, 'D': 56, 'Z': 57, 'u': 58, 'v': 59, 'J': 60, 'x': 61, 'U': 62}\n"
     ]
    }
   ],
   "source": [
    "print(char_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_batch(seq_length,p):\n",
    "    inputs = [char_id[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_id[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "    inputs=np.array(inputs).reshape(seq_length,1)\n",
    "    targets=np.array(targets).reshape(seq_length,1)\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test generator function here\n",
    "def generator(seed_i,n):\n",
    "    x=np.zeros((1,1))\n",
    "    x[0][0]= seed_i\n",
    "    ixes=[]\n",
    "    ixes.append(seed_i[0])\n",
    "    for t in range(n):\n",
    "        p=sess.run(prediction,{X:x})\n",
    "        ix = np.random.choice(range(unique_chars), p=p.ravel())\n",
    "        x[0][0]=ix\n",
    "        ixes.append(ix)\n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(x):\n",
    "    keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "    with tf.name_scope('rnn'):\n",
    "        cells= [tf.contrib.rnn.BasicRNNCell(num_units=HIDDEN_DIM,activation=tf.nn.tanh)\n",
    "            for layer in range(LAYER_NUM)]\n",
    "        cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "              for cell in cells]\n",
    "        multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells_drop)\n",
    "        outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype=tf.float32)\n",
    "        return outputs,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_LSTM(x):\n",
    "    keep_prob = tf.placeholder_with_default(0.2, shape=())\n",
    "    with tf.name_scope('lstm'):\n",
    "        cells= [tf.contrib.rnn.BasicLSTMCell(num_units=HIDDEN_DIM,activation=tf.nn.relu)\n",
    "            for layer in range(LAYER_NUM)]\n",
    "        cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "              for cell in cells]\n",
    "        multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "        outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype=tf.float32)\n",
    "        return outputs,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X=tf.placeholder(tf.uint8,[None,1])\n",
    "Y=tf.placeholder(tf.uint8,[None,1])\n",
    "\n",
    "X_onehot=tf.one_hot(X,unique_chars)\n",
    "Y_onehot=tf.one_hot(Y,unique_chars)\n",
    "\n",
    "outputs,states=build_LSTM(X_onehot)\n",
    "outputs=tf.transpose(outputs,perm=[1,0,2])\n",
    "\n",
    "W=tf.Variable(tf.truncated_normal((HIDDEN_DIM,unique_chars),-1,1))\n",
    "B=tf.Variable(tf.ones((1,unique_chars)))\n",
    "Ys=tf.matmul(outputs[0],W)+B\n",
    "\n",
    "prediction=tf.nn.softmax(Ys)\n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y_onehot, logits=Ys)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "    minimize = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_of_batches=int(total_chars//BATCH_SIZE)\n",
    "ptr=0\n",
    "# with tf.Session() as sess:\n",
    "#     smooth_loss = -np.log(1.0/unique_chars)*BATCH_SIZE # loss at iteration 0\n",
    "#     sess.run(init)\n",
    "#     for i in range(NB_EPOCH):\n",
    "#         for j in range(no_of_batches):\n",
    "#             if ptr+BATCH_SIZE+1 >= len(data): \n",
    "#                 ptr=0\n",
    "#             inputs,targets=generate_next_batch(BATCH_SIZE,ptr)\n",
    "#             ptr+=BATCH_SIZE\n",
    "#             if(j%100==0):\n",
    "#                 loss_t=sess.run(loss,feed_dict={X:inputs, Y:targets}) \n",
    "#                 sample_ix=generator(inputs[0],200)\n",
    "#                 txt = ''.join(id_char[ix] for ix in sample_ix)\n",
    "#                 smooth_loss = smooth_loss * 0.999 + loss_t * 0.001\n",
    "#                 print('epoch %i iteration %i loss %f'%(i,j,smooth_loss))\n",
    "#                 print ('----\\n %s \\n----' % (txt, ))\n",
    "#             sess.run(minimize,feed_dict={X:inputs,Y:targets})\n",
    "#     save_path = saver.save(sess, \"/tmp/RNNmodel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     smooth_loss = -np.log(1.0/unique_chars)*BATCH_SIZE # loss at iteration 0\n",
    "#     sess.run(init)\n",
    "#     for i in range(NB_EPOCH):\n",
    "#         for j in range(no_of_batches):\n",
    "#             if ptr+BATCH_SIZE+1 >= len(data): \n",
    "#                 ptr=0\n",
    "#             inputs,targets=generate_next_batch(BATCH_SIZE,ptr)\n",
    "#             ptr+=BATCH_SIZE\n",
    "#             if(j%100==0):\n",
    "#                 loss_t=sess.run(loss,feed_dict={X:inputs, Y:targets}) \n",
    "#                 sample_ix=generator(inputs[0],200)\n",
    "#                 txt = ''.join(id_char[ix] for ix in sample_ix)\n",
    "#                 smooth_loss = smooth_loss * 0.999 + loss_t * 0.001\n",
    "#                 print('epoch %i iteration %i loss %f'%(i,j,smooth_loss))\n",
    "#                 print ('----\\n %s \\n----' % (txt, ))\n",
    "#             sess.run(minimize,feed_dict={X:inputs,Y:targets})\n",
    "#         if (i%5==0):\n",
    "#             save_path = saver.save(sess, \"../LSTMmodel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    smooth_loss = -np.log(1.0/unique_chars)*BATCH_SIZE # loss at iteration 0\n",
    "    sess.run(init)\n",
    "    for i in range(NB_EPOCH):\n",
    "        for j in range(no_of_batches):\n",
    "            if ptr+BATCH_SIZE+1 >= len(data): \n",
    "                ptr=0\n",
    "            inputs,targets=generate_next_batch(SEQ_LENGTH,ptr)\n",
    "            ptr+=BATCH_SIZE\n",
    "            if(j%100==0):\n",
    "                loss_t=sess.run(loss,feed_dict={X:inputs, Y:targets}) \n",
    "                sample_ix=generator(inputs[0],150)\n",
    "                txt = ''.join(id_char[ix] for ix in sample_ix)\n",
    "                smooth_loss = smooth_loss * 0.999 + loss_t * 0.001\n",
    "                print('epoch %i iteration %i loss %f'%(i,j,smooth_loss))\n",
    "                print ('----\\n %s \\n----' % (txt, ))\n",
    "            sess.run(minimize,feed_dict={X:inputs,Y:targets})\n",
    "        if (i%5==0):\n",
    "            save_path = saver.save(sess, \"../LSTMmodel2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
