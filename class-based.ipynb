{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='data/shakespeare.txt'\n",
    "BATCH_SIZE=25\n",
    "LAYER_NUM=2\n",
    "SEQ_LENGTH=50\n",
    "HIDDEN_DIM=128\n",
    "GENERATE_LEN=500\n",
    "NB_EPOCH=1500\n",
    "MODE='train'\n",
    "WEIGHTS=''\n",
    "LEARNING_RATE=1e-1\n",
    "IS_TRAIN=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data():\n",
    "    with open(DATA_DIR,\"r\") as text_file:\n",
    "        data=text_file.read()\n",
    "        tr_data,va_data=data[0:1070392],data[1070392:1075392]\n",
    "    lis=list(set(data))    \n",
    "    total_char,unique_char=len(data),len(lis)\n",
    "    print ('data has %d characters, %d unique.' %(total_char, unique_char))\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(lis) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(lis) }\n",
    "    return data\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115393 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "data=get_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/coding2.json') as file:\n",
    "    da=json.load(file)\n",
    "    total_chars,vocab_size,char_id,id_char=da['total'],da['unique'],da['char_id'],da['id_char']\n",
    "\n",
    "id_v={int(k):v for k,v in id_char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_batch(given_data, seq_length, p):\n",
    "    inputs = [char_id[ch] for ch in given_data[p:p+seq_length]]\n",
    "    targets = [char_id[ch] for ch in given_data[p+1:p+seq_length+1]]\n",
    "    inputs=np.array(inputs).reshape(1,seq_length)\n",
    "    targets=np.array(targets).reshape(1,seq_length)\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr=0\n",
    "batches=(total_chars//SEQ_LENGTH)\n",
    "x=[]\n",
    "y=[]\n",
    "for batch in range(batches):\n",
    "    a,b=generate_next_batch(data, SEQ_LENGTH, ptr)\n",
    "    x.append(a)\n",
    "    y.append(b)\n",
    "    ptr+=SEQ_LENGTH\n",
    "x=np.array(x).reshape(batches, SEQ_LENGTH)\n",
    "y=np.array(y).reshape(batches, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22307, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_placeholders(batch_size,seq_length):\n",
    "        # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, seq_length], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, seq_length], name='targets')\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM(lstm_size, num_layers, batch_size): \n",
    "    \n",
    "    with tf.name_scope('lstm'):\n",
    "        cells= [tf.contrib.rnn.BasicLSTMCell(num_units=lstm_size) \n",
    "                for layer in range(num_layers)]\n",
    "        multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "#         batch_size_T  = np.shape(x)[0]\n",
    "        _initial_state =  multi_layer_cell.zero_state(batch_size, tf.float32)\n",
    "    return multi_layer_cell, _initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(lstm_output, hidden_dim, out_size):\n",
    "\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, hidden_dim])\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal([hidden_dim, out_size],stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros([out_size]))\n",
    "    \n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits, targets, lstm_size, vocab_size):\n",
    "    \n",
    "    y_one_hot = tf.one_hot(targets, vocab_size)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_reshaped, logits=logits))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(loss, learning_rate, grad_clip=5):\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, vocab_size, batch_size=25, seq_length=50, hidden_dim=128, num_layers=1, \n",
    "                 learning_rate=0.001, grad_clip=5, sampling=False):\n",
    "    \n",
    "        if sampling == True:\n",
    "            batch_size, seq_length = 1, 1\n",
    "        else:\n",
    "            batch_size, seq_length = batch_size, seq_length\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs, self.targets = get_placeholders(batch_size,seq_length)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        multi_cell, self.initial_state = build_LSTM(hidden_dim, num_layers=num_layers, batch_size=batch_size)\n",
    "        \n",
    "        x_one_hot = tf.one_hot(self.inputs, vocab_size)\n",
    "        \n",
    "        outputs, state = tf.nn.dynamic_rnn(multi_cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        self.prediction, self.logits = output(outputs, hidden_dim, vocab_size)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = loss(self.logits, self.targets, hidden_dim,vocab_size)\n",
    "        self.optimizer = optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(vocab_size, batch_size=BATCH_SIZE, seq_length=SEQ_LENGTH,\n",
    "                hidden_dim=HIDDEN_DIM, num_layers=LAYER_NUM, \n",
    "                learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'lstm/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(25, 128) dtype=float32>, h=<tf.Tensor 'lstm/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(25, 128) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'lstm/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(25, 128) dtype=float32>, h=<tf.Tensor 'lstm/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(25, 128) dtype=float32>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_batches=int(len(x)//BATCH_SIZE)\n",
    "ptr=0\n",
    "iteration=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100...  Training Step: 0...  Training loss: 4.173634...  0.4713 sec/batch\n",
      "Epoch: 1/100...  Training Step: 100...  Training loss: 3.276871...  0.1138 sec/batch\n",
      "Epoch: 1/100...  Training Step: 200...  Training loss: 3.433408...  0.1312 sec/batch\n",
      "Epoch: 1/100...  Training Step: 300...  Training loss: 3.417367...  0.1328 sec/batch\n",
      "Epoch: 1/100...  Training Step: 400...  Training loss: 3.317386...  0.1303 sec/batch\n",
      "Epoch: 1/100...  Training Step: 500...  Training loss: 3.230923...  0.1354 sec/batch\n",
      "Epoch: 1/100...  Training Step: 600...  Training loss: 3.369838...  0.1332 sec/batch\n",
      "Epoch: 1/100...  Training Step: 700...  Training loss: 3.472124...  0.1326 sec/batch\n",
      "Epoch: 1/100...  Training Step: 800...  Training loss: 3.519495...  0.1306 sec/batch\n",
      "Epoch: 2/100...  Training Step: 900...  Training loss: 3.652961...  0.1302 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1000...  Training loss: 3.326007...  0.1341 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1100...  Training loss: 3.685049...  0.1326 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1200...  Training loss: 3.280157...  0.1304 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1300...  Training loss: 3.514677...  0.1328 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1400...  Training loss: 3.359962...  0.1348 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1500...  Training loss: 3.288301...  0.1309 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1600...  Training loss: 3.627784...  0.1332 sec/batch\n",
      "Epoch: 2/100...  Training Step: 1700...  Training loss: 3.505813...  0.1224 sec/batch\n",
      "Epoch: 3/100...  Training Step: 1800...  Training loss: 3.713319...  0.1313 sec/batch\n",
      "Epoch: 3/100...  Training Step: 1900...  Training loss: 3.404323...  0.1334 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2000...  Training loss: 3.501612...  0.1138 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2100...  Training loss: 3.407799...  0.1377 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2200...  Training loss: 3.434841...  0.1336 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2300...  Training loss: 3.735898...  0.1294 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2400...  Training loss: 3.176364...  0.1324 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2500...  Training loss: 3.296635...  0.1292 sec/batch\n",
      "Epoch: 3/100...  Training Step: 2600...  Training loss: 3.433913...  0.1374 sec/batch\n",
      "Epoch: 4/100...  Training Step: 2700...  Training loss: 3.303834...  0.1316 sec/batch\n",
      "Epoch: 4/100...  Training Step: 2800...  Training loss: 3.311087...  0.1330 sec/batch\n",
      "Epoch: 4/100...  Training Step: 2900...  Training loss: 3.902776...  0.1321 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3000...  Training loss: 3.508189...  0.1138 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3100...  Training loss: 3.409504...  0.1166 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3200...  Training loss: 3.689564...  0.1195 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3300...  Training loss: 3.309592...  0.1173 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3400...  Training loss: 3.258146...  0.1313 sec/batch\n",
      "Epoch: 4/100...  Training Step: 3500...  Training loss: 3.556939...  0.1132 sec/batch\n",
      "Epoch: 5/100...  Training Step: 3600...  Training loss: 3.634079...  0.1122 sec/batch\n",
      "Epoch: 5/100...  Training Step: 3700...  Training loss: 3.564734...  0.1288 sec/batch\n",
      "Epoch: 5/100...  Training Step: 3800...  Training loss: 3.837743...  0.1323 sec/batch\n",
      "Epoch: 5/100...  Training Step: 3900...  Training loss: 3.403747...  0.1126 sec/batch\n",
      "Epoch: 5/100...  Training Step: 4000...  Training loss: 3.547654...  0.1141 sec/batch\n",
      "Epoch: 5/100...  Training Step: 4100...  Training loss: 3.551970...  0.1378 sec/batch\n",
      "Epoch: 5/100...  Training Step: 4200...  Training loss: 3.262504...  0.1138 sec/batch\n",
      "Epoch: 5/100...  Training Step: 4300...  Training loss: 3.520573...  0.1158 sec/batch\n",
      "Epoch: 5/100...  Training Step: 4400...  Training loss: 3.589684...  0.1163 sec/batch\n",
      "Epoch: 6/100...  Training Step: 4500...  Training loss: 4.108236...  0.1333 sec/batch\n",
      "Epoch: 6/100...  Training Step: 4600...  Training loss: 3.689931...  0.1136 sec/batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4bf5c389c2d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m                                                  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                                  model.optimizer], \n\u001b[1;32m---> 26\u001b[1;33m                                                  feed_dict=feed)\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(vocab_size, batch_size=BATCH_SIZE, seq_length=SEQ_LENGTH,\n",
    "                hidden_dim=HIDDEN_DIM, num_layers=LAYER_NUM, \n",
    "                learning_rate=LEARNING_RATE)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for i in range(no_of_batches):\n",
    "            if (ptr+BATCH_SIZE+1 >= batches): \n",
    "                ptr=0\n",
    "            inputs,targets=x[ptr:ptr+BATCH_SIZE],y[ptr:ptr+BATCH_SIZE]\n",
    "            ptr+=BATCH_SIZE\n",
    "            start=time.time()\n",
    "            feed = {model.inputs: inputs,\n",
    "                    model.targets: targets,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            end = time.time()\n",
    "            if(iteration%100==0):\n",
    "                print('Epoch: %i/%i... '%(e+1, epochs),\n",
    "                      'Training Step: %i... '%iteration,\n",
    "                      'Training loss: %f... '%batch_loss,\n",
    "                      '{:.4f} sec/batch'.format(end-start))\n",
    "            iteration+=1\n",
    "        if (e % 2 == 0):\n",
    "            saver.save(sess, \"checkk/i{}_l{}.ckpt\".format(iteration, HIDDEN_DIM))\n",
    "    \n",
    "    saver.save(sess, \"checkk/i{}_l{}.ckpt\".format(counter, HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(vocab_size, hidden_dim=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = char_id[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, vocab_size)\n",
    "        samples.append(id_v[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds,vocab_size)\n",
    "            samples.append(id_v[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkk/i4460_l128.ckpt\n",
      "Far\n",
      "\n",
      "\n",
      "\n",
      "zHz\n",
      "\n",
      "??zH?d?\n",
      "zzdd\n",
      "z?\n",
      "\n",
      "\n",
      "HHHz\n",
      "z?z?\n",
      "??d?z?dd\n",
      "\n",
      "\n",
      "H?H\n",
      "?\n",
      "\n",
      "d??\n",
      "z?\n",
      "zH???ddz?zz?\n",
      "d\n",
      "\n",
      "?\n",
      "H\n",
      "?H?zz\n",
      "z?\n",
      "?\n",
      "??z\n",
      "dz\n",
      "HHH\n",
      "H?dHddzzdH\n",
      "?\n",
      "\n",
      "\n",
      "H\n",
      "H?z?H??H\n",
      "HzHH\n",
      "dd?H\n",
      "\n",
      "H?Hzzd\n",
      "dz\n",
      "\n",
      "HHH?\n",
      "\n",
      "zzddzHz\n",
      "zdH?\n",
      "z\n",
      "zd?\n",
      "zH???\n",
      "?\n",
      "??\n",
      "?dHzz???Hd?\n",
      "z?zd\n",
      "zH?HHzd\n",
      "?\n",
      "zd??H?\n",
      "Hdd\n",
      "z?H?z?\n",
      "Hzzz\n",
      "\n",
      "?z?H???H\n",
      "z?d?HH\n",
      "d\n",
      "\n",
      "dH???????Hd??\n",
      "\n",
      "\n",
      "zdzzz\n",
      "?H??d?H\n",
      "\n",
      "??H??dHHHz\n",
      "?dz\n",
      "ddz\n",
      "z???H\n",
      "??H?zH\n",
      "?H\n",
      "?\n",
      "Hzzzzz\n",
      "?zdzz?HHd??????\n",
      "\n",
      "dzHz\n",
      "d??\n",
      "?\n",
      "??H\n",
      "??z?H?d??\n",
      "?H\n",
      "H?HH?\n",
      "??z\n",
      "H\n",
      "\n",
      "\n",
      "?\n",
      "\n",
      "??dd\n",
      "zd\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dz?\n",
      "z?\n",
      "?d?\n",
      "z\n",
      "Hd???d\n",
      "zHzdzH?dz??zzdd?\n",
      "?ddz?d??z?zHHHH?z?H\n",
      "?ddd\n",
      "zzzHz\n",
      "?HzzH\n",
      "Hz?d\n",
      "\n",
      "zz?\n",
      "\n",
      "dd\n",
      "zdH\n",
      "??\n",
      "?\n",
      "HH?Hd\n",
      "\n",
      "zzHz?z?H\n",
      "\n",
      "\n",
      "?zH?z???H?zH???dHHz\n",
      "zz\n",
      "?\n",
      "d??dHzHzHz\n",
      "dHzd\n",
      "?z??zd\n",
      "HH\n",
      "dz?\n",
      "\n",
      "\n",
      "?H\n",
      "\n",
      "?\n",
      "d\n",
      "HHz?\n",
      "\n",
      "\n",
      "?H?z\n",
      "?\n",
      "zHHzz??\n",
      "Hz?Hz??H\n",
      "\n",
      "HzH??HHHH?HzH\n",
      "H\n",
      "?zz?HHz\n",
      "zz\n",
      "?\n",
      "\n",
      "d?z\n",
      "?dHH?\n",
      "d?\n",
      "?HHdzz??\n",
      "\n",
      "z?zd?z\n",
      "\n",
      "ddz\n",
      "??HH\n",
      "H\n",
      "ddH??\n",
      "\n",
      "?\n",
      "d\n",
      "?\n",
      "?z\n",
      "?dz\n",
      "\n",
      "\n",
      "?d\n",
      "z?\n",
      "HzH???\n",
      "H?d??\n",
      "HzzHd?d\n",
      "z?HH\n",
      "??Hz\n",
      "Hz??d?z??zzHd??d?\n",
      "H?z?\n",
      "\n",
      "\n",
      "\n",
      "?\n",
      "\n",
      "\n",
      "?z???z\n",
      "d??H?\n",
      "H\n",
      "\n",
      "\n",
      "zdHdzd\n",
      "H?\n",
      "?\n",
      "H\n",
      "Hz\n",
      "z?ddzzd\n",
      "zddd\n",
      "zdHzzH\n",
      "\n",
      "H?\n",
      "?\n",
      "z\n",
      "H\n",
      "z???zz\n",
      "H?HH?H\n",
      "zH\n",
      "dHzd?d\n",
      "z\n",
      "HHdz\n",
      "z\n",
      "\n",
      "\n",
      "\n",
      "Hd\n",
      "?H\n",
      "Hz\n",
      "z??\n",
      "\n",
      "zd\n",
      "?\n",
      "\n",
      "z\n",
      "\n",
      "\n",
      "H?Hdzd\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "?d\n",
      "zHH\n",
      "z\n",
      "dHz?\n",
      "HdH\n",
      "Hzz?H\n",
      "z\n",
      "Hzzd?z?\n",
      "\n",
      "?zdz\n",
      "d?\n",
      "H??z?H?zzz\n",
      "d\n",
      "\n",
      "\n",
      "\n",
      "H?dd?z\n",
      "\n",
      "HH?d\n",
      "\n",
      "??H?z\n",
      "\n",
      "?d\n",
      "z\n",
      "\n",
      "??\n",
      "??\n",
      "z?zdH\n",
      "?zd?zz\n",
      "HdzdHz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "H?dH\n",
      "z?zzz\n",
      "???d\n",
      "H?dHz?H?Hz\n",
      "\n",
      "??dz\n",
      "d?\n",
      "?\n",
      "HHzd\n",
      "?\n",
      "?\n",
      "HH?zzHH?\n",
      "dz\n",
      "???\n",
      "?z\n",
      "zHd\n",
      "zHd\n",
      "\n",
      "d?\n",
      "z\n",
      "zzd??d\n",
      "?d\n",
      "?zz\n",
      "\n",
      "?z\n",
      "zHd\n",
      "zz???dz?\n",
      "\n",
      "\n",
      "zz\n",
      "\n",
      "dz?\n",
      "H?H\n",
      "HzH??\n",
      "H?dH\n",
      "?\n",
      "\n",
      "zd?Hzdd\n",
      "????Hz?z\n",
      "\n",
      "?d\n",
      "dHzzzd?z\n",
      "\n",
      "??zz??d\n",
      "z\n",
      "\n",
      "z?zzd?\n",
      "dzzz??z\n",
      "zz\n",
      "??\n",
      "H\n",
      "\n",
      "HH?HzHHzd?Hdd\n",
      "\n",
      "Hd?\n",
      "dzz?z\n",
      "\n",
      "\n",
      "z?H\n",
      "\n",
      "?\n",
      "z\n",
      "?dzHd?zddHz?HHH??\n",
      "\n",
      "\n",
      "\n",
      "d?\n",
      "?\n",
      "z???dH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "z\n",
      "\n",
      "zHHH\n",
      "?zd\n",
      "?\n",
      "z?\n",
      "d\n",
      "zz?\n",
      "\n",
      "\n",
      "\n",
      "?d\n",
      "\n",
      "?Hz\n",
      "?d\n",
      "zz??????d\n",
      "\n",
      "?H\n",
      "dHH\n",
      "?H\n",
      "\n",
      "d\n",
      "H\n",
      "z\n",
      "z?\n",
      "Hz?z\n",
      "\n",
      "H?zH\n",
      "\n",
      "H\n",
      "?\n",
      "?H\n",
      "?z\n",
      "??H\n",
      "d\n",
      "?\n",
      "z\n",
      "???Hd\n",
      "?\n",
      "H??\n",
      "?HHdd?z?\n",
      "???\n",
      "?H?dd\n",
      "\n",
      "\n",
      "dHzz??\n",
      "zd\n",
      "H\n",
      "\n",
      "\n",
      "?Hzd?z?Hz???H\n",
      "zz\n",
      "\n",
      "d?\n",
      "z\n",
      "H?\n",
      "??\n",
      "d\n",
      "d\n",
      "\n",
      "\n",
      "??\n",
      "\n",
      "?HH\n",
      "z\n",
      "?z\n",
      "z\n",
      "\n",
      "zH\n",
      "\n",
      "??Hz\n",
      "z\n",
      "?z\n",
      "?H??d\n",
      "zd?\n",
      "zz\n",
      "zH?d\n",
      "d\n",
      "?HH\n",
      "?\n",
      "z?\n",
      "zd?ddzH?\n",
      "??H?zHd?ddH\n",
      "H?dHH?\n",
      "d\n",
      "\n",
      "zd?H\n",
      "dzd?\n",
      "z??\n",
      "z\n",
      "zdHz?z??\n",
      "?\n",
      "zH\n",
      "H\n",
      "\n",
      "z?\n",
      "dH?\n",
      "?\n",
      "?zz\n",
      "\n",
      "zzzHH\n",
      "?dz?zHzH\n",
      "Hz?Hd\n",
      "HHH?HH?\n",
      "zH?d\n",
      "\n",
      "z?\n",
      "\n",
      "z?dH\n",
      "\n",
      "Hz?H?z\n",
      "\n",
      "\n",
      "z?\n",
      "d?ddH\n",
      "\n",
      "z\n",
      "\n",
      "\n",
      "z\n",
      "Hzd\n",
      "?zzHdzHH?\n",
      "?z\n",
      "Hd\n",
      "H?zd\n",
      "\n",
      "?\n",
      "\n",
      "zzzd\n",
      "z\n",
      "??\n",
      "H?zddH\n",
      "zd\n",
      "zd?\n",
      "?H?z??????\n",
      "?zzzH\n",
      "?\n",
      "H\n",
      "?dd\n",
      "dz??HHd\n",
      "?z?H\n",
      "\n",
      "?\n",
      "\n",
      "\n",
      "??zH\n",
      "d\n",
      "H\n",
      "z?HHdH??dHd\n",
      "\n",
      "?zz?d?\n",
      "zz?zd\n",
      "d?\n",
      "?\n",
      "d\n",
      "\n",
      "?z???d?\n",
      "dz\n",
      "\n",
      "HHz???zHz\n",
      "d?\n",
      "\n",
      "??\n",
      "\n",
      "z???\n",
      "\n",
      "?zdH?d\n",
      "H\n",
      "\n",
      "zH?zzHH?zz\n",
      "dd\n",
      "z\n",
      "\n",
      "H\n",
      "dz\n",
      "\n",
      "?\n",
      "HH\n",
      "HHd\n",
      "z??zdzHd\n",
      "z?d?\n",
      "?z?\n",
      "dHH??H\n",
      "H??\n",
      "??z?Hzzz\n",
      "?zd??\n",
      "\n",
      "z\n",
      "\n",
      "\n",
      "zH\n",
      "\n",
      "??z?HHH??d\n",
      "H?z\n",
      "HHHz?zd?z?HdH\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkk/')\n",
    "samp = sample(checkpoint, 2000, HIDDEN_DIM, vocab_size, prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ':',\n",
       " 1: 'W',\n",
       " 2: \"'\",\n",
       " 3: 'x',\n",
       " 4: 'G',\n",
       " 5: 'f',\n",
       " 6: 'm',\n",
       " 7: 'w',\n",
       " 8: '&',\n",
       " 9: 'a',\n",
       " 10: 'n',\n",
       " 11: 'q',\n",
       " 12: '.',\n",
       " 13: 't',\n",
       " 14: '3',\n",
       " 15: 'S',\n",
       " 16: 'g',\n",
       " 17: 'B',\n",
       " 18: 'T',\n",
       " 19: 'Y',\n",
       " 20: 's',\n",
       " 21: 'L',\n",
       " 22: '\\n',\n",
       " 23: 'i',\n",
       " 24: '?',\n",
       " 25: '$',\n",
       " 26: 'c',\n",
       " 27: 'A',\n",
       " 28: ';',\n",
       " 29: '-',\n",
       " 30: ' ',\n",
       " 31: ',',\n",
       " 32: 'R',\n",
       " 33: 'y',\n",
       " 34: 'N',\n",
       " 35: '!',\n",
       " 36: 'V',\n",
       " 37: 'E',\n",
       " 38: 'X',\n",
       " 39: 'o',\n",
       " 40: 'e',\n",
       " 41: 'z',\n",
       " 42: 'k',\n",
       " 43: 'O',\n",
       " 44: 'r',\n",
       " 45: 'Q',\n",
       " 46: 'd',\n",
       " 47: 'Z',\n",
       " 48: 'b',\n",
       " 49: 'v',\n",
       " 50: 'j',\n",
       " 51: 'D',\n",
       " 52: 'F',\n",
       " 53: 'p',\n",
       " 54: 'h',\n",
       " 55: 'l',\n",
       " 56: 'U',\n",
       " 57: 'P',\n",
       " 58: 'J',\n",
       " 59: 'M',\n",
       " 60: 'I',\n",
       " 61: 'K',\n",
       " 62: 'u',\n",
       " 63: 'C',\n",
       " 64: 'H'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
